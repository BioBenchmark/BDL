##  benchmark results (RES entities)

Evaluation of benchmarks will produce outputs with formats specified in FT entities. The output files will be processed by summarizers to generate summary statistics that will be saved to RES entities. Although computational tools can have different output file types, summarizers can extract the same type of information from those output files, allowing comparisons of benchmark results across computational tools and reference datasets.

The “ground truth” of datasets and properties of outputs summarized by relevant summarizers allow comparison of performance between computational tools. While a ground truth makes it easier to compare computational tool performance, the ground truth of datasets with no known signal can still be used if comparing with a currently accepted method or “gold standard” (e.g., fluorescence in situ hybridization to validate absolute copy number predictions (69)) or an overlap of signals detected by multiple methods (70). CBL does not treat ground truth as a special property or entity. If present, ground truths can be saved as a RES entity from a hypothesized computational tool and be used to compare the performance of other computational tools.
